{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make your own custom environment\n",
    "\n",
    "This documentation overviews creating new environments and relevant\n",
    "useful wrappers, utilities and tests included in Gymnasium designed for\n",
    "the creation of new environments.\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Recommended solution\n",
    "\n",
    "1. Install ``pipx`` following the [pipx documentation](https://pypa.github.io/pipx/installation/).\n",
    "2. Then install Copier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipx\n",
      "  Downloading pipx-1.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting argcomplete>=1.9.4 (from pipx)\n",
      "  Downloading argcomplete-3.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: colorama>=0.4.4 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from pipx) (0.4.6)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from pipx) (24.1)\n",
      "Requirement already satisfied: platformdirs>=2.1 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from pipx) (4.3.6)\n",
      "Collecting userpath!=1.9,>=1.6 (from pipx)\n",
      "  Downloading userpath-1.9.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: click in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from userpath!=1.9,>=1.6->pipx) (8.1.7)\n",
      "Downloading pipx-1.7.1-py3-none-any.whl (78 kB)\n",
      "Downloading argcomplete-3.5.1-py3-none-any.whl (43 kB)\n",
      "Downloading userpath-1.9.2-py3-none-any.whl (9.1 kB)\n",
      "Installing collected packages: argcomplete, userpath, pipx\n",
      "Successfully installed argcomplete-3.5.1 pipx-1.7.1 userpath-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!py -m pip install --user pipx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'copier' already seems to be installed. Not modifying existing installation in\n",
      "'C:\\Users\\gaojin\\pipx\\venvs\\copier'. Pass '--force' to force installation.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: copier in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (9.4.1)\n",
      "Requirement already satisfied: colorama>=0.4.6 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from copier) (0.4.6)\n",
      "Requirement already satisfied: dunamai>=1.7.0 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from copier) (1.23.0)\n",
      "Requirement already satisfied: funcy>=1.17 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from copier) (2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.4 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from copier) (3.1.4)\n",
      "Requirement already satisfied: jinja2-ansible-filters>=1.3.1 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from copier) (1.3.2)\n",
      "Requirement already satisfied: packaging>=23.0 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from copier) (24.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from copier) (0.12.1)\n",
      "Requirement already satisfied: plumbum>=1.6.9 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from copier) (1.9.0)\n",
      "Requirement already satisfied: pydantic>=2.4.2 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from copier) (2.9.2)\n",
      "Requirement already satisfied: pygments>=2.7.1 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from copier) (2.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from copier) (6.0.2)\n",
      "Requirement already satisfied: questionary>=1.8.1 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from copier) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from jinja2>=3.1.4->copier) (3.0.1)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from plumbum>=1.6.9->copier) (308)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.4.2->copier) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.4.2->copier) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.4.2->copier) (4.12.2)\n",
      "Requirement already satisfied: prompt_toolkit<=3.0.36,>=2.0 in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from questionary>=1.8.1->copier) (3.0.36)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\gaojin\\appdata\\roaming\\python\\python312\\site-packages (from prompt_toolkit<=3.0.36,>=2.0->questionary>=1.8.1->copier) (0.2.13)\n",
      "C:\\Users\\gaojin\\AppData\\Roaming\\Python\\Python312\\Scripts is already in PATH.\n",
      "Success! Added C:\\Users\\gaojin\\.local\\bin to the PATH environment variable.\n",
      "\n",
      "Consider adding shell completions for pipx. Run 'pipx completions' for\n",
      "instructions.\n",
      "\n",
      "You will need to open a new terminal or re-login for the PATH changes to take\n",
      "effect. Alternatively, you can source your shell's config file with e.g.\n",
      "'source ~/.bashrc'.\n",
      "\n",
      "Otherwise pipx is ready to go! ✨ 🌟 ✨\n"
     ]
    }
   ],
   "source": [
    "!pipx install copier\n",
    "!pip install copier\n",
    "!pipx ensurepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copier 9.4.1\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!copier --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，您只需运行以下命令并将字符串path/to/directory替换为要在其中创建新项目的目录的路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "这段只能在terminal中运行\n",
    "'''\n",
    "!copier copy https://github.com/Farama-Foundation/gymnasium-env-template.git \"./learn/my_env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subclassing gymnasium.Env 子类化gymnasium.Env\n",
    "\n",
    "为了说明子类化gymnasium.Env的过程，我们将实现一个非常简单的游戏，称为GridWorldEnv 。我们会写 我们的自定义环境的代码 gymnasium_env/envs/grid_world.py 。环境 由固定大小的二维方形网格组成（通过指定 施工时的size参数）。代理可以在每个时间步长的网格单元之间垂直或水平移动。代理的目标是导航到在剧集开始时随机放置的网格上的目标。\n",
    "\n",
    "-  观察提供了目标和代理的位置。\n",
    "-  我们的环境中有 4 个动作，分别对应于“右”、“上”、“左”和“下”运动。\n",
    "-  一旦代理导航到目标所在的网格单元，就会发出完成信号。\n",
    "-  奖励是二元且稀疏的，这意味着即时奖励始终为零，除非智能体已达到目标，否则为 1。\n",
    "  \n",
    "我们一块一块看一下GridWorldEnv的源代码：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaration and Initialization 声明和初始化\n",
    "\n",
    "我们的自定义环境将继承自抽象类 gymnasium.Env .您不应该忘记添加metadata 归属于你的class。在那里，您应该指定渲染模式 受您的环境支持（例如， \"human\" 、 \"rgb_array\" 、 \"ansi\" ）以及渲染环境的帧速率。每个环境都应该支持None作为渲染模式；您不需要将其添加到元数据中。在GridWorldEnv中，我们将支持“rgb_array”和“ human”模式并以 4 FPS 渲染。\n",
    "\n",
    "我们环境的__init__方法将接受整数 size ，决定方形网格的大小。我们将设置一些用于渲染的变量并定义self.observation_space和 self.action_space 。在我们的例子中，观察应该提供有关代理和目标在二维网格上的位置的信息。我们将选择以带有键\"agent\"和\"target\"的字典的形式表示观察结果。观察可能看起来像 {\"agent\": array([1, 0]), \"target\": array([0, 3])} 。由于我们的环境中有 4 个动作（“右”、“上”、“左”、“下”），因此我们将使用Discrete(4)作为动作空间。这是GridWorldEnv的声明和__init__的实现：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gymnasium_env/envs/grid_world.py\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "class Actions(Enum):\n",
    "    RIGHT = 0\n",
    "    UP = 1\n",
    "    LEFT = 2\n",
    "    DOWN = 3\n",
    "\n",
    "\n",
    "class GridWorldEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None, size=5):\n",
    "        self.size = size  # The size of the square grid\n",
    "        self.window_size = 512  # The size of the PyGame window\n",
    "\n",
    "        # Observations are dictionaries with the agent's and the target's location.\n",
    "        # Each location is encoded as an element of {0, ..., `size`}^2, i.e. MultiDiscrete([size, size]).\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {\n",
    "                \"agent\": spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "                \"target\": spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "            }\n",
    "        )\n",
    "        self._agent_location = np.array([-1, -1], dtype=int)\n",
    "        self._target_location = np.array([-1, -1], dtype=int)\n",
    "\n",
    "        # We have 4 actions, corresponding to \"right\", \"up\", \"left\", \"down\"\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "        \"\"\"\n",
    "        The following dictionary maps abstract actions from `self.action_space` to\n",
    "        the direction we will walk in if that action is taken.\n",
    "        i.e. 0 corresponds to \"right\", 1 to \"up\" etc.\n",
    "        \"\"\"\n",
    "        self._action_to_direction = {\n",
    "            Actions.RIGHT.value: np.array([1, 0]),\n",
    "            Actions.UP.value: np.array([0, 1]),\n",
    "            Actions.LEFT.value: np.array([-1, 0]),\n",
    "            Actions.DOWN.value: np.array([0, -1]),\n",
    "        }\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        \"\"\"\n",
    "        If human-rendering is used, `self.window` will be a reference\n",
    "        to the window that we draw to. `self.clock` will be a clock that is used\n",
    "        to ensure that the environment is rendered at the correct framerate in\n",
    "        human-mode. They will remain `None` until human-mode is used for the\n",
    "        first time.\n",
    "        \"\"\"\n",
    "        self.window = None\n",
    "        self.clock = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Observations From Environment States\n",
    "\n",
    "Since we will need to compute observations both in ``reset`` and\n",
    "``step``, it is often convenient to have a (private) method ``_get_obs``\n",
    "that translates the environment’s state into an observation. However,\n",
    "this is not mandatory and you may as well compute observations in\n",
    "``reset`` and ``step`` separately:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _get_obs(self):\n",
    "        return {\"agent\": self._agent_location, \"target\": self._target_location}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also implement a similar method for the auxiliary information\n",
    "that is returned by ``step`` and ``reset``. In our case, we would like\n",
    "to provide the manhattan distance between the agent and the target:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _get_info(self):\n",
    "        return {\n",
    "            \"distance\": np.linalg.norm(\n",
    "                self._agent_location - self._target_location, ord=1\n",
    "            )\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oftentimes, info will also contain some data that is only available\n",
    "inside the ``step`` method (e.g., individual reward terms). In that case,\n",
    "we would have to update the dictionary that is returned by ``_get_info``\n",
    "in ``step``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset\n",
    "\n",
    "将调用reset方法来启动新的episode。您可以假设在调用reset之前不会调用step方法。此外，只要发出完成信号，就应该调用reset 。用户可以传递seed关键字进行reset以将环境使用的任何随机数生成器初始化为确定性状态。建议使用环境基类gymnasium.Env提供的随机数生成器self.np_random 。如果你只使用这个RNG，你不需要太担心种子，但你需要记住调用``super().reset(seed=seed)``以确保gymnasium.Env 正确为 RNG 播种。完成后，我们可以随机设置 我们的环境状况。在我们的例子中，我们随机选择代理 位置和随机样本目标位置，直到不 与代理人的职位相符。\n",
    "\n",
    "reset方法应该返回初始观察的元组和一些辅助信息。我们可以使用方法_get_obs和 我们之前为此实现的_get_info ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reset(self, seed=None, options=None):\n",
    "        # We need the following line to seed self.np_random\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Choose the agent's location uniformly at random\n",
    "        self._agent_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "\n",
    "        # We will sample the target's location randomly until it does not coincide with the agent's location\n",
    "        self._target_location = self._agent_location\n",
    "        while np.array_equal(self._target_location, self._agent_location):\n",
    "            self._target_location = self.np_random.integers(\n",
    "                0, self.size, size=2, dtype=int\n",
    "            )\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step\n",
    "\n",
    "step方法通常包含您环境的大部分逻辑。它接受一个action ，计算该动作的状态 应用该操作后的环境并返回 5 元组 (observation, reward, terminated, truncated, info) 。看 gymnasium.Env.step() 。一旦新的环境状态出现 计算完毕后，我们可以检查它是否是最终状态，然后我们设置 相应地done 。由于我们在中使用稀疏二元奖励 GridWorldEnv ，一旦我们知道，计算reward就微不足道了 done 。为了收集observation和info ，我们可以再次使用_get_obs和_get_info ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def step(self, action):\n",
    "        # Map the action (element of {0,1,2,3}) to the direction we walk in\n",
    "        direction = self._action_to_direction[action]\n",
    "        # We use `np.clip` to make sure we don't leave the grid\n",
    "        self._agent_location = np.clip(\n",
    "            self._agent_location + direction, 0, self.size - 1\n",
    "        )\n",
    "        # An episode is done iff the agent has reached the target\n",
    "        terminated = np.array_equal(self._agent_location, self._target_location)\n",
    "        reward = 1 if terminated else 0  # Binary sparse rewards\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, reward, terminated, False, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering\n",
    "\n",
    "在这里，我们使用 PyGame 进行渲染。 Gymnasium 中包含的许多环境都使用类似的渲染方法，您可以将其用作您自己的环境的骨架：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode(\n",
    "                (self.window_size, self.window_size)\n",
    "            )\n",
    "        if self.clock is None and self.render_mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        pix_square_size = (\n",
    "            self.window_size / self.size\n",
    "        )  # The size of a single grid square in pixels\n",
    "\n",
    "        # First we draw the target\n",
    "        pygame.draw.rect(\n",
    "            canvas,\n",
    "            (255, 0, 0),\n",
    "            pygame.Rect(\n",
    "                pix_square_size * self._target_location,\n",
    "                (pix_square_size, pix_square_size),\n",
    "            ),\n",
    "        )\n",
    "        # Now we draw the agent\n",
    "        pygame.draw.circle(\n",
    "            canvas,\n",
    "            (0, 0, 255),\n",
    "            (self._agent_location + 0.5) * pix_square_size,\n",
    "            pix_square_size / 3,\n",
    "        )\n",
    "\n",
    "        # Finally, add some gridlines\n",
    "        for x in range(self.size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (0, pix_square_size * x),\n",
    "                (self.window_size, pix_square_size * x),\n",
    "                width=3,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (pix_square_size * x, 0),\n",
    "                (pix_square_size * x, self.window_size),\n",
    "                width=3,\n",
    "            )\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            # The following line copies our drawings from `canvas` to the visible window\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            # We need to ensure that human-rendering occurs at the predefined framerate.\n",
    "            # The following line will automatically add a delay to keep the framerate stable.\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:  # rgb_array\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close\n",
    "\n",
    "close方法应该关闭环境使用的所有开放资源。在许多情况下，您实际上不必费心去实现此方法。然而，在我们的示例中， render_mode可能是 \"human\" ，我们可能需要关闭已打开的窗口：\n",
    "在其他环境中， close还可能关闭已打开的文件或释放其他资源。调用close后，您不应该与环境交互。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering Envs\n",
    "\n",
    "为了让 Gymnasium 检测到自定义环境，他们 必须按如下方式注册。我们将选择将此代码放入 gymnasium_env/__init__.py 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.envs.registration import register\n",
    "\n",
    "register(\n",
    "    id=\"gymnasium_env/GridWorld-v0\",\n",
    "    entry_point=\"gymnasium_env.envs:GridWorldEnv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "环境 ID 由三个组件组成，其中两个是可选的：可选的命名空间（此处： gymnasium_env ）、强制名称（此处： GridWorld ）和可选但推荐的版本（此处：v0）。它也可能已注册为GridWorld-v0 （推荐的方法）、 GridWorld或gymnasium_env/GridWorld ，然后在环境创建期间应使用适当的 ID。\n",
    "\n",
    "关键字参数max_episode_steps=300将确保通过gymnasium.make实例化的GridWorld环境将被包装在TimeLimit包装器中（有关更多信息，请参阅包装器文档）。如果智能体已达到目标或在当前情节中已执行 300 个步骤，则会产生完成信号。要区分截断和终止，您可以检查info[\"TimeLimit.truncated\"] 。\n",
    "\n",
    "除了id和entrypoint之外，您还可以将以下附加关键字参数传递给register ：\n",
    "\n",
    "+----------------------+-----------+-----------+---------------------------------------------------------------------------------------------------------------+\n",
    "| Name                 | Type      | Default   | Description                                                                                                   |\n",
    "+======================+===========+===========+===============================================================================================================+\n",
    "| ``reward_threshold`` | ``float`` | ``None``  | The reward threshold before the task is  considered solved                                                    |\n",
    "+----------------------+-----------+-----------+---------------------------------------------------------------------------------------------------------------+\n",
    "| ``nondeterministic`` | ``bool``  | ``False`` | Whether this environment is non-deterministic even after seeding                                              |\n",
    "+----------------------+-----------+-----------+---------------------------------------------------------------------------------------------------------------+\n",
    "| ``max_episode_steps``| ``int``   | ``None``  | The maximum number of steps that an episode can consist of. If not ``None``, a ``TimeLimit`` wrapper is added |\n",
    "+----------------------+-----------+-----------+---------------------------------------------------------------------------------------------------------------+\n",
    "| ``order_enforce``    | ``bool``  | ``True``  | Whether to wrap the environment in an  ``OrderEnforcing`` wrapper                                             |\n",
    "+----------------------+-----------+-----------+---------------------------------------------------------------------------------------------------------------+\n",
    "| ``kwargs``           | ``dict``  | ``{}``    | The default kwargs to pass to the environment class                                                           |\n",
    "+----------------------+-----------+-----------+---------------------------------------------------------------------------------------------------------------+\n",
    "\n",
    "大多数这些关键字（除了max_episode_steps ， order_enforce和kwargs ）不会改变环境实例的行为，而只是提供一些有关您的环境的额外信息。注册后，我们自定义的GridWorldEnv 环境可以创建为 env = gymnasium.make('gymnasium_env/GridWorld-v0') .\n",
    "\n",
    "如果您的环境未注册，您可以选择传递一个要导入的模块，这将在创建环境之前注册您的环境，如下所示 - env = gymnasium.make('module:Env-v0') ，其中module 包含注册码。对于 GridWorld 环境，注册 代码是通过导入gymnasium_env来运行的，所以如果不可能 显式导入gymnasium_env，您可以在制作时注册 env = gymnasium.make('gymnasium_env:gymnasium_env/GridWorld-v0') 。当您被允许仅将环境 ID 传递到第三方代码库（例如学习库）时，这尤其有用。这使您可以注册您的环境，而无需编辑库的源代码。\n",
    "\n",
    "``gymnasium_env/envs/__init__.py`` should have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium_env.envs.grid_world import GridWorldEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Package\n",
    "\n",
    "最后一步是将我们的代码构建为 Python 包。这涉及配置pyproject.toml 。如何执行此操作的最小示例如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[build-system]\n",
    "requires = [\"hatchling\"]\n",
    "build-backend = \"hatchling.build\"\n",
    "\n",
    "[project]\n",
    "name = \"gymnasium_env\"\n",
    "version = \"0.0.1\"\n",
    "dependencies = [\n",
    "  \"gymnasium\",\n",
    "  \"pygame==2.1.3\",\n",
    "  \"pre-commit\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # run_gymnasium_env.py\n",
    "\n",
    "   import gymnasium\n",
    "   import gymnasium_env\n",
    "   env = gymnasium.make('gymnasium_env/GridWorld-v0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Creating Environment Instances\n",
    "\n",
    "现在您可以使用以下命令在本地安装软件包：\n",
    ".. code:: console\n",
    "\n",
    "   pip install -e .\n",
    "\n",
    "您可以通过以下方式创建环境实例：\n",
    "\n",
    "\n",
    "您还可以将环境构造函数的关键字参数传递给 gymnasium.make自定义环境。在我们的例子中，我们可以这样做：\n",
    ".. code:: python\n",
    "\n",
    "   env = gymnasium.make('gymnasium_env/GridWorld-v0', size=10)\n",
    "\n",
    "有时，您可能会发现跳过注册并自己调用环境的构造函数更方便。有些人可能会发现这种方法更Pythonic，并且像这样实例化的环境也非常好（但也要记住添加包装器！）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using Wrappers\n",
    "\n",
    "通常，我们想要使用自定义环境的不同变体，或者我们想要修改 Gymnasium 或其他方提供的环境的行为。包装器允许我们在不改变环境实现或添加任何样板代码的情况下做到这一点。查看包装器文档，了解如何使用包装器的详细信息以及实现您自己的包装器的说明。在我们的示例中，观察结果不能直接用于学习代码，因为它们是字典。然而，我们实际上不需要修改我们的环境实现来解决这个问题！我们可以简单地在环境实例之上添加一个包装器，将观察结果扁平化为单个数组："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import gymnasium_env\n",
    "from gymnasium.wrappers import FlattenObservation\n",
    "\n",
    "env = gymnasium.make('gymnasium_env/GridWorld-v0')\n",
    "wrapped_env = FlattenObservation(env)\n",
    "print(wrapped_env.reset())     # E.g.  [3 0 3 3], {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "包装器有一个很大的优势，那就是它们可以使环境变得高度 模块化的。例如，不是将观察结果展平 GridWorld，您可能只想查看 GridWorld 的相对位置 目标和代理。在关于 ObservationWrappers我们已经实现了一个完成这项工作的包装器。此包装也可用于 gymnasium_env/wrappers/relative_position.py :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import gymnasium_env\n",
    "from gymnasium_env.wrappers import RelativePosition\n",
    "\n",
    "env = gymnasium.make('gymnasium_env/GridWorld-v0')\n",
    "wrapped_env = RelativePosition(env)\n",
    "print(wrapped_env.reset())     # E.g.  [-3  3], {}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
